<%-
  cmd = "sinfo -ho %R"
  begin
    output, status = Open3.capture2e(cmd)
    if status.success?
      partitions = output.split("\n").map(&:strip).reject(&:blank?).sort
    else
      raise output
    end
  rescue => e
    partitions = []
    error = e.message.strip
  end
-%>

<%-
    paths = []
    paths << Pathname.new("/home/#{User.new.name}")
    paths << Pathname.new("/data/#{User.new.name}")
    paths << Pathname.new("/scratch/#{User.new.name}")

    projects = User.new.groups.map(&:name).grep(/^pg-./)

    paths.concat projects.map { |p| Pathname.new("/data/#{p}")  }
-%>

---
cluster: "peregrine"

form:
  - modules
  - extra_jupyter_args
  - node_type
  - cuda_version
#  - python_version
  - custom_queue
  - wall_time
  - num_cores
  - version
  - jupyterlab_switch
  - memory
  - start_folder
  - reservation
  - bc_email_on_started

attributes:
  wall_time:
    label: Wall time
    help: "Please give the wall time in the SLURM format, D-HH:MM:SS"
    widget: "text_field"

  memory:
    label: Memory
    help: Amount of memory requested, in GB
    widget: 'number_field'
    value: 2
    min: 1
    max: 128
    step: 1
  extra_jupyter_args: ""
  node_type: 'gpu'

  custom_queue:
    label: Partition
    help: Please select a partition from the drop-down menu.
  <%- if partitions.blank? -%>
    widget: text_field
  <%- else -%>
    widget: select
    options:
    <%- partitions.each do |q| -%>
      - [ "<%= q %>", "<%= q %>" ]
    <%- end -%>
  <%- end -%>
  
  start_folder:
    label: Notebook root folder
    help: Where should the jupyter server start?
  <%- if paths.blank? -%>
    widget: text_field
  <%- else -%>
    widget: select
    options:
    <%- paths.each do |q| -%>
      - [ "<%= q %>", "<%= q %>" ]
    <%- end -%>
  <%- end -%>
    
  num_cores:
    widget: "number_field"
    label: "Number of cores"
    value: 1
    id: 'num_cores'
    help: |
      Number of cores per node.
    min: 1
    max: 48
    step: 1

#  cuda_version:
#    widget: "select"
#    label: "CUDA Version"
#    help: |
#      CUDA is Nvidia's GPU-specific parallel computing framework. A GPU node
#      is required to make use of this functionality.
#    options:
#      - [ "CUDA/10.1.105", "CUDA/10.1.105-GCC-8.2.0-2.31.1" ]
  cuda_version: "CUDA/10.1.105-GCC-8.2.0-2.31.1"
  modules:
    widget: "select"
    label: "Python Version"
    help: |
      Select one of the Python versions from the dropdown.

      **If you select a GPU version, you also need to specify the GPU partition.**
    options:
      - [ "Python 3.6.4", "IPython/6.4.0-foss-2018a-Python-3.6.4" ]
      - [ "Python 3.6.4", "IPython/6.4.0-foss-2018a-Python-3.6.4" ]
      - [ "Python 3.7.2", "IPython/7.7.0-foss-2019a-Python-3.7.2" ]
      - [ "Python 3.7.4", "IPython/7.9.0-foss-2019b-Python-3.7.4" ]
      - [ "Python 3.7.4 GPU", "IPython/7.9.0-fosscuda-2019b-Python-3.7.4" ]
      - [ "Python 3.8.2", "IPython/7.15.0-foss-2020a-Python-3.8.2" ]
      - [ "Python 3.9.5", "IPython/7.18.1-GCCcore-10.3.0" ]
      - [ "R 3.6.1", "R/3.6.1-foss-2018a IPython/6.4.0-foss-2018a-Python-3.6.4 Pandoc/2.5" ]
  version: "jupyter/Python3.7"
  jupyterlab_switch: 0
  reservation: "xdmod-test"

